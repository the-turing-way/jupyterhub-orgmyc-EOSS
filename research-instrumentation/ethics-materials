**Ethics Materials**  
**The JupyterHub Community Strategic Lead (EOSS-D&I) with The Turing Way.**  
**September 2024**   
Relevant People 

- Arielle Bennett, Programme Manager, Tools, Practices & Systems, abennett@turing.ac.uk
- Kirstie Whitaker, Programme Director, Tools, Practices & Systems, kwhitaker@turing.ac.uk

Additional Parties

- Chris Holdgraf, Executive Director, 2i2c, [choldgraf@gmail.com](mailto:choldgraf@gmail.com)
- Dan Sholler, Senior Consultant, Organizational Mycology - Researcher/Consultant - [dan@orgmycology.com](mailto:dan@orgmycology.com)

The overall project is ongoing since 2022. The Turing Way’s involvement in the project is due to commence in October 2024 after ethics approval.  
 

### Purpose and Aims of Research

The Turing Way is collaborating with JupyterHub on a revision of their Essential Open-Source Software grant which has a no cost extension to December 2025. This grant was awarded to JupyterHub by the Chan Zuckerberg Initiative, but due to resourcing constraints, the PI Chris Holdgraf asked The Turing Way project team to collaborate on the funding extension due to our experience with research community building in open source. Organizational Mycology, an independent third-party are contracted to conduct the data collection as part of Work Package 1 (described in detail below) and produce a report as part of the output of the grant. 

JupyterHub is an open source project which provides computational notebooks to researchers, either in the cloud or on their own hardware. It gives users access to computational environments and resources without burdening the users with installation and maintenance tasks. Despite the fact that the main repo has been starred nearly 8,000 times, the project is maintained by volunteers. It is this community of volunteer maintainers we are focusing on for the study we are seeking ethics approval for. 

This study is intended to: 

* Identify successes, challenges and opportunities to improve team dynamics within the JupyterHub community
* Facilitate team process and workflow improvement conversations
* Identify on-ramp pathways for community members to become JupyterHub developers
* Develop strategies, processes, and techniques for holding welcoming, inclusive, and productive community events
* Support mentors and mentees in the community
* Inform the revision and improvement of the JupyterHub Team Compass

A major goal of the project is to innovate new ways of structuring open source contribution so that it is open and participatory. This means that there is a constant process of designing, learning, and refining ways of working and engaging with affected stakeholders, not just as research subjects but as fellow researchers

The Turing Way and JupyterHub will be collaborating with a third-party organisation: Organizational Mycology to conduct the primary research including interviews with community members, a quantitative community survey and research on publicly available forum discussion data. There are four key workstreams defined below. 

***Note:*** We consider work package 1 to be research activities as aligned with the Turing’s definition of “eligible research”. We believe this is eligible research because the approach will use semi-structured interviews outside of a regular meeting schedule, as well as a survey and open discussions to elucidate recommendations to improve diversity in the community. This approach should mitigate the potential for power dynamics to impact the data collected. In addition, we are seeking ethics approval to make a dataset of quotes available for reuse in other similar projects in the future at other organisations. 

Work packages 2, 3 and 4 are implementation activities that will deliver real world impact as a result of the research in WP1. There is the potential for findings and practices developed as a result of this research to have a wider impact on other open source projects practices as well.  
We are asking for ethics approval for the activities in WP1 - specifically qualitative information gained from the leadership workshops, the semi-structured interviews, community survey, and publicly available discussions - but include a description of WP2-4 to support an understanding of the project as a whole.

WP1: Develop a community engagement strategy and identify current blockers to contributor participation 

* Initiate a Community Improvement Assessment to identify challenges and opportunities to improve team dynamics within the JupyterHub community. In addition, begin work with *The Turing Way* team to understand how its practices and principles could be applied to the JupyterHub community. This will become an ongoing effort at identifying opportunities for improvement.
* Facilitate two leadership workshops for the JupyterHub Council focused on 1) challenges, 2) opportunities, and 3) actions related to building a diverse community.
* Conduct interviews with JupyterHub community members to understand how our community development strategy could be improved.
  * Include members of the Steering Council, non-maintainer community members, and previous contributors who have decided not to remain in the community.
* Develop a community survey to test the generalisability of learnings from the semi-structured interviews with JupyterHub community members, and track the impact of any interventions and process improvements over time.
  * The survey will allow for long term monitoring of the diversity and inclusive engagement of members of the JupyterHub community, including understanding how new people join and are retained and supported over time.
* Use publicly available data from issues, pull requests and discussion posts on JupyterHub, The Turing Way, and Jupyter GitHub repositories, and from discussion forums including Discourse.

WP2: Community development guide  
Rather than create an independent community development guide we will focus on updating *The Turing Way* and the existing JupyterHub Team Compass. These tasks have been slightly adjusted to reflect this pivot from a stand alone community development guide.

* Document the strategy identified above, as well as provide details for how team members should implement this strategy.
* Prepare and polish the JupyterHub Team Compass so that it contains all of the lessons learned from our experiences thus far.
* Refine *The Turing Way* chapters relating to project design, community engagement, code review, and running inclusive online events, so they do not have to be repeated in the JupyterHub Team Compass.
* Generalize the JupyterHub governance and decision making processes into The Turing Way so that other open source communities can more easily discover processes that they can fork and modify for their own use.
* Create a strategy around developer on-ramp pathways. For example, this may include our strategy around internship programs, events for new contributors, or team processes that invite new contributions (e.g., using “good first issue” labels)

WP3: Develop and adapt training for community members to mentor new contributors 

* Identify and implement major team process and workflow improvements (e.g., GitHub Issue labels, milestones, etc) that make it easier for others to participate.
* Develop events guides for running team events that broaden participation (e.g., issue tackling parties), potentially in partnership with other members of the Jupyter community (like the Jupyter events manager).
* Create strategy around supporting team members in mentorship roles. This may include how to give our team the proper training they need to support others, and defining structure and mentorship for them to succeed.

WP4: Embed inclusive practices in the JupyterHub community 

* Act as steward over the new team processes that were identified in year 1, to ensure they are being followed and have a positive impact.
* Plan for the next phase of the *Community Strategic Lead* role beyond the end of this funding, in partnership with others in the JupyterHub team.

	 

**Planned outputs:**  
**WP1:** 

* ‘Voices of JupyterHub’ report
* Dataset of qualitative interview responses as described elsewhere in this document
* Two workshops for JupyterHub leadership

**WP2:**  
Expanded, revised, and updated chapters of The Turing Way and JupyterHub’s Team Compass on GitHub  
**WP3:** 

* Events guide for JupyterHub which supports more inclusive participation
* Revised strategy document for community mentorship

**WP4:**

* Strategic plan for next phase of the JupyterHub’s efforts to improve its community diversity

## Ethical Considerations


### Describe Project Methods and Data

*Ways in which the methods and datasets representative, relevant, accurate and generalisable.* 

The Turing Way and JupyterHub will be collaborating with a third-party organisation: Organizational Mycology to conduct the primary research including two leadership workshops, interviews with community members, a quantitative community survey and research on publicly available forum discussion data. 

- **Grant PI, Chris Holdgraf**, is a member of **JupyterHub leadership** and will provide oversight of all work packages as well as community context for Work Packages 1-4. **Min Ragan-Kelley,** another member of the **JupyterHub leadership** team, will be responsible for delivering Work Package 4.
- **Kristie Whitaker**, collaborator, is the leader of **The Turing Way**, and will be responsible for delivering Work Packages 1, 2 & 3.
- **Organizational Mycology**, the third party organisation, have been sub-contracted to deliver Work Package 1, in partnership with The Turing Way.

The main goal of the project is to document voices in the JupyterHub community and examine community successes, challenges, and opportunities for improvement in the areas listed in Section 2.9. Accordingly, the sample will be limited to members of the JupyterHub community and insights will largely be tailored to the community’s goals, rather than seeking to be generalizable. Since the overarching objective is to identify blockers to contributions to JupyterHub as well as opportunities to improve contribution pathways and develop potential contributors, interacting directly with the community to gather data ensures that it is representative and relevant. However, some findings may be relevant to other open source projects seeking to improve the overall diversity and vibrancy of their contributor communities by adopting some of the practices and recommendations developed in WP2-4, which will be based on the findings in WP1.

### Recruitment Strategy

Estimates for the number of participants in each workstream are below.

* Organizational Mycology intend to engage with **26 to 28 community members in the interview stage**. They will balance their engagements to cover active developers and contributors, non-active developers and contributors (e.g., community members who interact with the community but do not contribute; formerly active contributors), and members of JupyterHub’s leadership team. Below are estimates of the number of people from each group:
  * 10 to 15 active developers/contributors to assess successes and challenges in their pathways to becoming developers/contributors (i.e., developer on-ramp pathways), their experience playing this role in the community, and opportunities for improvement of their experience.
  * 5 to 10 community members who are not active developers/contributors to identify barriers and challenges to contribution
  * 6 to 8 members of the JupyterHub leadership team to identify potential team process and workflow improvements.
* Leadership workshop: Organizational Mycology and JupyterHub have identified **roughly 20 potential attendees** for the leadership workshop based on publicly-available information (JupyterHub’s website and communications) and previous work. They will invite as many of these leaders to the workshop as funding allows. When making decisions about who to include, they will consider the following factors and strive to achieve balance on each dimension:
  * Level of experience, in years
  * Role (e.g., software/technical, community)
  * Perceived or self-reported demographics, with a particular focus on gender identification, geographic location, and race/ethnicity
  * Availability

When possible, Organizational Mycology will solicit asynchronous contributions from leaders who are unable to attend the workshop. This might include sharing meeting notes documents and requesting responses to prompts in those documents or feedback on the outcomes of the workshop.

* Survey: It is difficult to predict what the response rate of any given survey will be. The survey will be open to all JupyterHub community members who actively view the communication spaces used by the community (e.g., Slack, mailing lists, and forums). We will also include a request for respondents to share the survey via word-of-mouth to generate a larger snowball sample. **We anticipate the number of respondents to range from 75 to 300 individuals**. If the response rate is unexpectedly low, we will revise our approach and seek guidance from the ethics review team on our approach.

Challenges for representation will include: ensuring that community members from a variety of backgrounds, expertise levels, and involvement in the project are included in data collection; collecting data on those missing from the community, who might contribute but cannot/do not due to the existing barriers; and enabling potential participants to participate with as little interference to their day-to-day work as possible. To mitigate some of these challenges, we will proactively reach out to members of the community throughout the duration of the project (i.e., over the course of several months), provide opportunities to participate using video conferencing software, and offer participation time slots that meet their preferences and accommodate their work and personal responsibilities. 

Organizational Mycology will recruit participants in both passive and active ways, with assistance from The Turing Way and JupyterHub. 

The passive approach is intended to enable a wide variety of community members to participate without feeling coerced or discouraged. Aligning with best-practices in recruitment, we will post advertisements for participation in several public community spaces. These advertisements will include links to the public Scope of Work, the consent form, and published materials from prior components of the study (e.g., the  on:

* Slack
* Forum
* Collaboration Cafes

In the active approach, we will directly email or message members of the community to gauge their interest in participation. We believe this targeted approach is necessary and reasonable for two main reasons: First, the JupyterHub community is relatively small when compared to communities such as open source software or a large scientific discipline. We therefore need to ensure that both prominent and “hidden” voices are represented in the data. Second, from our perspective, the procedures involve minimal risk to the participant and the researcher and potential benefits are substantial. We will therefore directly reach out to:

* Leadership groups
* Maintainer/core contributor lists

If we hear a “no”, we will promptly stop asking and remove them from the recruitment materials. 

### Diversity of Engagement

We will take several steps to ensure that we have engaged with a variety of people and adapt our recruitment approach based on what we learn. These steps will include:

* Advertising the call for participation on all possible communication forums
* Requesting that participants inform us or their peers about the opportunity to participate, particularly encouraging these participants to think about people who might have a unique or underrepresented view on the topics we cover
* Attending JupyterHub collaboration cafe events to share intermediate findings and make attendees aware of opportunities to participate
* Seeking feedback on preliminary findings via our shared GitHub repository, which will include information on how to participate and add voices to our data collection effort
* Actively updating our understanding of the size (and potential size) of the JupyterHub community and ensuring that the number of participants in proportional to the size of the community

Our goal is to share as much about our data collection efforts and our preliminary findings with the community as openly as possible. Sharing these materials and updates is perhaps the most critical mechanism to ensure that we are hearing from the people who can best help us answer our research questions.

The research team is well-versed in considering differences in backgrounds and expertise levels, geographic and cultural nuances, power differentials in communities, and potential participant vulnerabilities (e.g., contingent, early career labor; unbalanced gender, age, and race/ethnicity dynamics). 

The qualitative interview approach ensures the dataset gathered is as accurate as possible for the perspective provided by the person interviewed. This will be cross-referenced with a quantitative survey and publicly available forum discussion data from [GitHub](https://github.com/jupyterhub),  to support conclusions with different data sources. Anonymised datasets will be made available online for future researchers, with more detail on these plans in 3.3 and 3.21. Draft research questions for the qualitative interviews have been included in Appendix III. 

Responses across all workstreams will inform the development of the outputs described in the Scope of Work. The general approach will be as follows:

* Voices of JupyterHub
  * Interviews will be audio recorded and transcribed.
  * We will then apply qualitative coding techniques to generate themes insights (see Strauss, A., & Corbin, J. M. (1990). *Basics of qualitative research: Grounded theory procedures and techniques.* Sage Publications, Inc. and Miles, M. B., & Huberman, A. M. (1994). *Qualitative data analysis: An expanded sourcebook* (2nd ed.). Sage Publications, Inc.). Put simply, qualitative data analysis involves layering interpretation onto the data by first identifying commonalities and differences in responses to the same or similar questions. After identifying these commonalities and differences, a codebook is developed to deepen the analysis, breaking themes down further into subthemes. Codes are applied to snippets of text where these themes appear. As an example, in this project, initial themes may include “contributor challenges” and “first contribution.” These themes may then be broken down into “contributor challenges - conflict with employment responsibilities; contributor challenges - time famine” and “first contribution - documentation; first contribution - code.” Final stages of analysis involves linking these codes to one another. For example, we may link the contributor challenge of time famine to difficulties making code contributions vs. documentation contributions.
  * We will report these themes and any relevant contextual information in our outputs. When participants have consented, we will include representative quotes from interviews to substantiate our claims.
  * We will triangulate our findings using the results of the survey and notes or other materials from the leadership workshop. We may, for example, link challenges identified by contributors in interviews to decisions made by the leadership team (e.g., elements of contribution guidelines enabling or inhibiting community members from contributing) and report the scale of the problem (or opportunity) using results from the survey. Triangulation using multiple types of data is an essential component of qualitative research and will be prominent in all of our outputs.

* Other methods of processing and sharing data
  * For interview responses, we will structure our notes and/or transcripts by interviewee or participant, identifying each transcript / notes document by a unique participant ID. These transcripts / notes will be qualitatively coded in a structured way using a database system with lines / discussion from the notes / transcripts which are relevant to the research coded and flagged for inclusion in a public data set.
  * The work of qualitatively coding the interviews will start with applying a qualitative code book to topics discussed by participants as described above, followed by a second step where coders select whether or not the quote will be included in the public dataset based on participant choices in the informed consent form. Before publishing any participant data, participants will have the opportunity to redact or remove data they do not wish to have included.
  * Throughout this process, all transcripts and notes will default to no data sharing. As we code and apply participant’s choices during the coding process, we will enable data sharing on a line-by-line basis in the notes / transcript documents. We will then use automated data filtering methods based on this include / exclude flag to create a data export which includes only the content which is appropriate to share under our ethical plan. We will conduct a manual review before release to ensure all quotes exported meet our ethical plan.
* For reporting and qualitative analysis, we will draw from the complete dataset, but we will only include specific quotes where participants have explicitly opted in to their voices being directly shared. Using all approved-for-sharing data, we will create a repository that contains quotes and other relevant information for the public. This repository will enable the JupyterHub community to manage a lasting, potentially expandable dataset of perspectives, views and quotes for use in community development efforts, grant applications and reporting, presentations and demos, and other efforts.
* Survey data will be analyzed in accordance with best-practices, particularly using basic analysis tools to visualize results. Bar charts, for example, may be used to illustrate the proportion of responses to a given question. Open-ended responses will be used similarly to interview quotes. These results will be put into conversation with all other data sources in our reporting.

Across all workstreams, Organizational Mycology will draw upon decades of experience doing qualitative research in academic and applied settings. This experience includes expertise in tailoring methods to research questions, triangulation, and member-checking (i.e., soliciting feedback from participants and knowledgeable community members to assess the validity of our findings). Likewise, ethical decisions will be treated with care: Our team has completed ethics training, IRB protocols and study approval, courses on methods and ethics, and engaged with responsible research working groups at nearly a dozen different universities and colleges. We have been active members and leaders of groups who operate under rigorous ethical principles, privacy and security standards, and respect for research participants. Working in tandem with the Alan Turing Institute, we will strive to ensure that we are held accountable for our data collection, analysis, and reporting choices, including continuous engagement with the ethics team, active feedback from participants and community members, open working styles, and standard reporting mechanisms as outlined in the informed consent documentation.

Although much of the work focuses on one community, which may make it less generalisable to other open-source communities, work will be carried out to consider what can be generalised from the findings as part of WP2-4. Making a set of the semi-structured interview data publicly available, subject to participants consent, will also support future research on similar topics in other communities.

### Describe the recency of your dataset

The qualitative interview data and quantitative survey data used for the project will be gathered as part of the project methodology. Therefore, it can be considered recent data.  
There is a possibility that publicly accessible forum data which is collected misses detail and context, as posts can be deleted or edited, or may also reflect conversations happening in spaces which are not captured on the public record. The project will therefore use public forum posts only in conjunction with the primary data collected and present findings from analysis as part of a body of evidence, rather than relying solely on this dataset.  
Forum posts and other archival data will be limited to the previous five years (2019 to present) to ensure findings are primarily relevant to the current community.  

**Data Provenance**

*An overview of the data provenance, data procurement, pre-processing, lineage, storage, and security of the dataset(s), including the methods for maintaining a record of this information throughout the project lifecycle.*

**Data provenance and procurement:** The datasets will be collected by Organizational Mycology.

* Interview data will be collected over the period of the project. Dan Sholler, Beth Duckles, and Jonah Duckles will conduct, record, transcribe, and analyze the interview data. For each interview, the date and time (in the interviewer’s geographic location) and location (e.g., videoconference) will be recorded.
* Archival data (e.g., forum posts, mailing lists) will be collected over the period of the project. Dan Sholler, Beth Duckles, and Jonah Duckles will collect these data. These communications will have taken place over the previous 5 years. When collecting this data, the date and time of the communication will be recorded.
* Survey data will be collected over the period of the project. Dan Sholler, Beth Duckles, and Jonah Duckles will collect these data. The date and time of responses will be recorded.
* Notes and collaborative artifacts (e.g., photos of whiteboards, sticky notes, diagrams, etc.) will be collected from the Leadership Workshops by Dan Sholler, Beth Duckles, and Jonah Duckles. We will store these materials on the private Google Drive and reference them in producing deliverables for the project. The date and time of the workshops will be recorded.

**Preprocessing:** 

* Interview recordings will be transcribed using a local GPU using WhisperX. Transcripts will be loaded into a private Google Drive with access only available to the Organizational Mycology team. Transcripts will be loaded into qualitative data analysis software on local machines. Transcript excerpts will be placed in a spreadsheet on the same Drive during the analysis phase.
* Archival data will be collected in the export format of the platform used for the communication (e.g., PDFs for email lists; PDFs or CSVs for online forums). These data will be handled in the same way as interview transcripts, described above.
* Survey data will be collected using Google Forms and/or Typeform. Responses will be exported as a CSV file, stored in the private Google Drive, and analyzed on local machines.
* Notes and collaborative artifacts from the Leadership Workshops will be preserved in their original form, but we will also pull from these materials to create summaries and identify common themes from the workshop. This preprocessing will aid in extracting actionable insights from the workshops.

**Lineage:**

* Data will be collected, stored, and analyzed by the Organizational Mycology team as described above. Excerpts from the interview, archival, survey data, and leadership workshop notes and artifacts will be communicated in reports. Excerpts will also be stored and shared when approved by the research participant, as described in the research participation consent form. See the relevant passages at Appendix I.
* Two years after the final publication from the project, all remaining data that is not being retained due to participant choices or due to irrelevance will be destroyed.
* We will create a public repository with participant-approved excerpts from interviews and surveys. This repository will represent the experiences of the participants on topics deemed relevant to the study (e.g., contributor/developer pathways, diversity and inclusion, and workflows). The data contained in this repository will be available for future research and related uses. The repository will be hosted on GitHub. Participants who agree to have excerpts shared will have the opportunity to review and/or remove content prior to publishing.

**Storage & Security:**  
·         Organizational Mycology will be storing recordings off cloud in a storage system which encrypts the files at rest on local disks.  
·         Encrypted archives / snapshots of this data will be stored in backblaze B2 for disaster recovery purposes.  
·         Recordings will be transcribed using a local GPU using WhisperX and transcripts themselves will be worked on using a private Google Drive with access only available to the Organizational Mycology team.  
 

### Data Organization

*Overview of how the data was labelled, annotated, organised, or classified, including the processes in place to review classifications if they were outsourced or automated.*  
No outsourced classifications take place.  
Data about personal experiences of open source contribution to JupyterHub will be classified in the following ways:  
1.   	Data will be labelled according to whether it is a description of the user’s own experience or an observation/inference about another’s experience. This will be according to the user’s own reporting.  
2.   Data will be categorised into data which is usable for research purposes and data which is to be published publicly. Some will fall into both categories, or neither. This is so that the preferences and agency of the users about their data are protected. We also give users the option to change their sharing preferences, allowing for a fine-grained, dynamic consent model to be put into practice.  
3.	Data will be categorised by abstracted participant role, including titles such as: “Leader,” “Maintainer,” “Developer,” “Contributor,” “User,” “Community Member,” etc. This may include multiple roles, as in the case of a User who becomes a Contributor or Maintainer. We will mitigate the risk of identification by applying this label only in a separate Participant Key and in the analysis spreadsheet, not on the interview transcript itself. In the case of surveys, participants will be asked to self-identify their role in the JupyterHub project and duration of their participation in the community.  
4.	Demographic data will only be collected in surveys by asking the participant to report any demographic characteristics they feel comfortable sharing via text boxes. As an example, we will phrase the question in a minimally-prescriptive way such as “Please provide any demographic or other personal characteristics you feel comfortable sharing, such as age, race/ethnicity, gender identity, sexual orientation).” In interviews, demographic data will be collected via open-ended questions. Interviewees may, for example, discuss their demographic characteristics in the course of an interview in response to questions about how their background shapes their experience, and we may then ask about their experience as a member of an underrepresented group. While potentially sensitive, this information is crucial for generating actionable insights for making the JupyterHub community a more diverse and inclusive environment. In analysis, we may then link self-reported demographic characteristics to other experiences and comments (e.g., identifying that community members from a specific group share similar challenges to participation).  
 

### Metadata

*Overview of the metadata, contextual information, or other documentation available, including whether this will be attached to the datasets and/or project output.*  
*Attaching contextual information and metadata to a project output enables appropriate downstream analyses of data processing, in terms of bias mitigation and reusability.*

Information pertaining to the project will be openly published on GitHub under open licenses: [https://github.com/the-turing-way/jupyterhub-orgmyc-EOSS](https://github.com/the-turing-way/jupyterhub-orgmyc-EOSS). Outputs will also be published in other persistent repositories such as Zenodo, which offer citable DOIs and standard metadata formats. Fictional example data will be provided to help guide potential users of the outputs as part of publishing the work. 

Identifying relevant metadata will depend in part on the type of data or output. For interview excerpts, for example, relevant metadata will include the participant’s role in the JupyterHub community, their career stage, their scientific discipline or industry, and any demographic data they share. For surveys, metadata will be based upon the questions asked but will include those listed for interviews. We will also include the research instruments (e.g., semi-structured interview protocol, survey questions, consent form) in the project repository, an explanation of our process for developing the instruments, a methods description for data collection and analysis, and the scope of work for this project.

We recognise all the information available may require some exploration and familiarisation with the project and repository. As no dataset has yet been created this details on the data has not been summarised in a succinct documentation, as data is collected from the project we will prepare and release metadata and other summaries. 


### Diverse Voices

*Overview of the processes the research team will use to ensure that diverse voices within the team are heard and engaged with during the design stage.*  
*Diverse and inclusive participation at the design phase of the project is important to ensure the acceptability of the project plan, and to assess the ethical impacts of the design choices made.*

The team has been working on the design of this project with members of the community from the beginning. The PI, Chris Holdgraf and co-I, Kirstie Whitaker, and collaborator Min Ragan-Kelley (JupyterHub) are long-standing contributors to JupyterHub, while other collaborators are contributors to *The Turing Way* or other open source communities themselves.  
The team have discussed their plans already in community spaces such as collaboration cafes, community calls, and posted in community forums to receive early feedback on plans. A major goal of the project is to innovate new ways of structuring open source contribution so that it is open and participatory. This means that there is a constant process of designing, learning, and refining ways of working and engaging with affected stakeholders, not just as research subjects but as fellow researchers.  
From a team perspective, each member of the team is recognised as an individual expert in different areas and with different skills to contribute to the project. *The Turing Way* in particular has long been a champion of research infrastructure roles, and recognising the benefits of a diverse team composition to drive equality and best practices in different areas of research forward. *The Turing Way* has [resources on addressing feedback when there are power imbalances](https://book.the-turing-way.org/collaboration/leadership/leadership-building) which will be utilised as needed, alongside the project's [Code of Conduct](https://book.the-turing-way.org/community-handbook/coc). JupyterHub has its own [Code of Conduct](https://github.com/jupyter/governance/blob/HEAD/conduct/code_of_conduct.md) which will be applied when in JupyterHub spaces.  
With this in mind, the approach for the project has been co-designed from the start with project managers and researchers equally contributing. We are committed to providing different avenues and channels for contributing to this project for community members so that they are able to utilise the one that best fits with their needs and preferences. The team is also empowered to adjust established methods to ensure that other needs not previously anticipated can also be accommodated. 

### Outcome Fairness

*Definition of “fairness” in terms of the project’s impacts and outcomes, including how this will be measured, and whether a Fairness Position Statement will be created and made available to affected stakeholders.*

The team has an initial fairness statement, available in Appendix II, which will be included on the GitHub repository for stakeholders and the public to read, following feedback from the Ethics review panel. 

### Biases

*Identification of biases that may be present across the project workflow and the bias risk mitigation actions to be taken, including whether a Bias Self-Assessment and Risk Management Template will be created and made available to affected stakeholders.*

The Organizational Mycology team has conducted research in a variety of open science communities and other organizations with diverse, fluid membership. The research team is therefore well-versed in considering differences in backgrounds and expertise levels, geographic and cultural nuances, power differentials in communities, and potential participant vulnerabilities (e.g., contingent, early career labor; unbalanced gender, age, and race/ethnicity dynamics). Organizational Mycology mitigates bias by accepting that biases are inherent in any social activity and identifying the ways in which those biases operate. We often see in our work, for example, that software communities tend to schedule community events with a bias toward North American or European schedules to the exclusion of community members elsewhere in the world. Likewise, the race/ethnicity and gender balance in these communities often overrepresents people who identify as White and/or men. In such cases, we seek to elevate the voices of the underrepresented groups, particularly their ideas about how to implement practices and processes that counteract homogeneity. An example of our efforts to do this can be found in a recent study of the Astropy open source software community, separated into two reports: [https://astropy-dei.orgmycology.com/](https://astropy-dei.orgmycology.com/) and [https://astropy-report.orgmycology.com/](https://astropy-report.orgmycology.com/) 

**Missing voices:** We are aware that there is a majority voice missing from community surveys and forum post analysis: those that might have become contributors but did not due to structural or personal barriers so never joined the community to add their voice. As the primary motivator for the project is improving contributor communities and their diversity, we are actively considering how best to reach out to people who might match this category to ensure they are represented as part of the reflexive analysis and practical change that is the intention of this project. 

**Institutional bias:** A key goal of this project is to help counteract institutional bias, particularly those that are persistent inside of computing and scientific disciplines and communities. Accordingly, we will strive to elevate the voices of participants from underrepresented groups when analyzing and reporting findings. We may, for example, center an experience held by just one or two members of the community when those experiences represent barriers that limit community participation. This practice runs somewhat counter to the common practice of reporting central themes that emerged across multiple participants in traditional social science research. It is essential to the goals of this project, however, to uncover these individual experiences to identify the systemic reasons they emerged (especially when experiences are unusually exclusionary/unwelcoming or inclusionary/welcoming).  

**Materials/Data Collection bias:** Despite our experience accommodating rather than obscuring potential sources of bias, we also accept that bias is in many ways inevitable: Our own identities shape the experience of our interviewees and research participants when interacting with us. We strive to make the experience more comfortable and, ideally, more responsible by reminding participants of their autonomy–they are free to withdraw, skip questions they find uncomfortable, challenge our interpretation of particular observations or incidents, and otherwise shape their participation in ways that best reflect their true experiences.  
In developing research instruments, we take additional steps to test and revise our semi-structured interview protocols, surveys, and other materials based on feedback from trusted experts and members of underrepresented groups. We often find ourselves revising a question to be more sensitive to the experiences of early career folks, for example, who may still be forming an opinion on a given topic; to be more relevant to folks who live and work in non-North American/European institutions where working arrangements and cultural norms of interaction differ; or to be more inviting of alternative opinions on a topic. By continually seeking this kind of feedback, the project and the team are in a constant re-evaluation of its methods, actions and ways of engagement. 

 

### Accountability

*Overview of each research team member’s roles and responsibilities in the project, including how these will be clearly assigned and maintained throughout the project lifecycle to ensure answerability.*

Project manager – responsible for keeping the project on track, coordinating meetings, managing the project budget and complying with institutional and funder policies, contributing to operational delivery of the project outputs.

Organizational Mycology researchers - As per the statement of work: conducting primary and secondary research, analysis of findings, and reporting recommendations based on the findings. Facilitation of the leadership meetings for the JupyterHub Council. 

Project leadership - named researchers, Kirstie Whitaker, Min Ragan-Kelley & Chris Holdgraf will meet once per month to oversee the direction of the project. Chris Holdgraf is accountable to the funder for providing annual updates on progress. Kirstie Whitaker is accountable to the Turing Institute for providing six monthly reports on progress to the Institute.

For the avoidance of doubt, Chris Holdgraf will make any final decisions if there are different proposed directions. However the team will endeavor to reach consensus through collaborative discussion at all times.

We intend to maintain the README file on the project GitHub repository as a record of assigned roles and responsibilities across the team. Version control will allow interested stakeholders to track changes made across the project lifecycle. In addition, use of GitHub as a project management tool will also enable stakeholders to trace individual actions of project members through contributions to the repository. 

Public presentations and attendance at community meet-ups planned also allow everyone to know the team and their roles first-hand.

### Governance

*Overview of the governance framework established for the project, including whether it will be made accessible for audit and review.*  
The team overall will endeavor to reach consensus through collaborative discussion at all times. However, for the avoidance of doubt, Chris Holdgraf, as project PI will make any final decisions if there are different proposed directions.  
In addition, working openly on GitHub as much as practicable offers the opportunity for audit and scrutiny by community members and stakeholders. Documents including updated project statement of work, goals, and activities, allows interested parties to trace all decisions and actions. Roles and responsibilities as described in 3.11 will also be documented on GitHub to make it clear who is generally responsible for different areas of the projects delivery.  
Adding tasks as issues on the GitHub repo allows interested parties to track progress, see who is assigned to specific tasks, and provide their own perspectives and input view comments on the issue where needed. This provides the infrastructure necessary for audit and answerability at any point.  
 

### Replicability

*Description of how the project will be made reproducible and/or replicable by other researchers, including whether data, analysis code, software, process logs, activity logs, or other similar records will be made publicly available.*

The team will develop an open publishing plan for both the anonymised, consented datasets, report findings and other resources developed during the project. Some resources and datasets will be published on Zenodo to provide persisting DOIs, others will be available on the GitHub repository.

Finally, findings from the initial report will also be adapted and referenced as part of *The Turing Way* project materials as part of the project deliverables, widening their dissemination.  
 

### Stakeholders

*Identification of the stakeholders, including individuals and social groups, who may be impacted by or may impact the project, with an indication of any groups particularly vulnerable to potential impacts.*

Main stakeholders in the project:

*  JupyterHub community members - these stakeholders are particularly vulnerable to impacts from implementing the findings of the project.
*  JupyterHub community leadership - these stakeholders are particularly vulnerable to impacts from implementing the findings of the project.
* The Turing Way community members
*  The Turing Way community leadership

Peripheral stakeholders

* Broader Jupyter community
* The funders – Chan Zuckerberg Initiative. We list the funders as stakeholders since they have an expressed interest in improving diversity, equity and inclusion overall in open source as part of their charitable objectives, they have a track record of not controlling what is published, or how decisions are made in projects that receive funding from them.
*  Other open source community members and potential members who can benefit from more systematic analysis of where improvements can be made to the contribution pathways of open source projects


### Impact

*Assessment of the real-world impact of the research project, including the potential benefits and harms to each identified stakeholder, and a description of the actions the team will take to mitigate potential risks.*

Our project is primarily focused on identifying real-world impact when it comes to community engagement, development and inclusion. We include the details of our proposed benefits through our implementation and impact pathways in the descriptions of work packages 2, 3 and 4 in answer 2.9 above.  
We do not anticipate any significant harms that will come from the outputs of our work. We acknowledge the challenge of describing exclusionary behaviours and barriers to participation which will likely include individual experiences of racism, sexism, ableism and colonialism. However it is aligned with the purpose of the project and funding call to draw attention to these experiences as a first step towards dismantling them and building a more inclusive open source community.  
The Organizational Mycology and TPS research team members have a track record in managing sensitive conversations and building inclusive spaces for the people affected by reports of bias. For example, Organizational Mycology have previously conducted similar work for another open source community, AstroPy ([report here](https://astropy-report.orgmycology.com/)), while TPS research members have published work on building a more inclusive [open research community](https://www.bps.org.uk/psychologist/bropenscience-broken-science) and [the need for professional roles to do so](https://arxiv.org/abs/2409.00108).  
While it is possible that the quotes we intend to publish in a de-identified form may be taken by others and used out of context to reinforce negative perceptions of JupyterHub or open source and research overall, we believe that the potential benefits of making such resources available to the wider community will outweigh potential harms. Accompanying documentation will make it clear that individual quotes should not be used as stand alone pieces of evidence, but incorporated into a holistic understanding of a complex ecosystem.  
 

### Stakeholder Engagement

*The level of stakeholder engagement your team will undertake for your project, and the methods you will use.*

We have already opened a GitHub issue on the JupyterHub team compass and plan to organise the project on the *Turing Way* organisation on GitHub so that community can track the progress of the project easily. The Organizational Mycology team will be attending community co-working and calls for both *The Turing Way* and JupyterHub both to observe and participate in the communities as part of working openly on the project.

At the very core of the project is stakeholder engagement with the JupyterHub community which will take the form of 1:1 voluntary interviews with community members. A follow up wider survey will gather a larger selection of views from the JupyterHub community. Both of these data gathering exercises will be cross-referenced with archival data from public forums to round out the picture of the community. Workshops for the JupyterHub leadership will build on initial findings. These stages will be co-designed with members of the JupyterHub leadership.  
Following information gathering, Organizational Mycology will deliver a report with recommendations on community engagement and development pathways for JupyterHub.  
Once this stage has been completed, the JupyterHub community leadership will look at the findings and recommendations and be responsible for translating these into actionable procedures for the community to improve its diversity and contributor base. *The Turing Way* community will also work to translate these to generalisable insights for other communities in the open source space to draw on as a resource. Both communities are at the centre of developing the outputs of this project.  

### Environmental Sustainability

*Overview of the possible positive and negative environmental impacts of the project, including actions the team will take to mitigate potential risks.*

The project is not expected to generate a comparatively large amount of data or to use computationally expensive algorithms to analyse it, so the additional environmental costs of storage and compute are relatively low.  
The majority of the work will take place remotely via online collaboration, reducing carbon emissions from the need to travel to conduct the research, but not eliminating the environmental impact of utilising technology.  
However, the overall grant does plan for two in-person workshops for the JupyterHub leadership during the course of the project. This will require people to fly to a single location which will have a negative environmental impact in terms of the carbon emitted by the flights. To mitigate this, remote facilitation will be offered for people wishing to join online, and the project will explore the possibility of using some funding for carbon offsetting.


### Technical Sustainability

*Description of how the team will ensure accuracy, reliability, security, and robustness in the research project methods.*

Accuracy and reliability will be ensured by recruiting and collecting data only from participants who are active or previously active members of the JupyterHub community. When possible, we will triangulate findings between multiple sources of data (e.g., if an incident in the community or change in the organisation is mentioned in an interview, we will look to other interviews, forum posts, project announcements, and other sources to confirm the participant’s recollection). As with any social science research, there is always the risk of participants misremembering or fabricating experiences. When we suspect this to be the case after consulting other sources, we will exclude the relevant data from the dataset.  
Data security will be ensured by taking the steps described in Section 3.3 above.  
To ensure robustness, we will engage in ongoing member-checking. Prior to releasing a report, for example, we will circulate it among participants in the research project. We will also draw on the past experiences of the research team doing this type of work, ensuring that findings are generated and presented in ways that align with best-practices for qualitative research (e.g., noting when a finding reflects the experience of one individual vs. a broader theme reported by a substantial portion of participants).  
 

### Researcher Wellbeing

*Overview of any potential risks to the researchers’ wellbeing and safety posed by the research project, including a description of those risks and the measures to mitigate them.*

We anticipate there will be minimal risks to researcher wellbeing as part of the methodologies employed (primary research interviews, quantitative community survey and forum archival research). Reputational risk exists to the researchers, as some participants may have negative feelings about the interview experience. We will minimise this risk by including the option to withdraw from participation at any time in the research participation consent form as well as reaffirming this option verbally before the interview begins. Likewise, when potentially sensitive questions arise, we will remind the participant that they may skip any question or line of inquiry.  
We acknowledge that it is possible for findings to be uncovered which cause distress or discomfort to members of the community or leadership.  
To minimise the risks to participants in the 1:1 survey, Organizational Mycology, as a neutral third-party will be conducting interviews and providing findings as anonymised or pseudoanonymised results.  
 

### Process Transparency

*Description of how the team will demonstrate consideration of ethical permissibility, fairness, safety, and public trustworthiness during the project design, development, and implementation processes, if questioned by external parties.*

The project has been discussed with both *The Turing Way* and JupyterHub communities prior to work commencing. Issues have been opened on the JupyterHub team compass repo, to present interim findings from the first stage of the project and propose this current phase publicly, well in advance of work beginning.  
Team members have attended community calls and collaboration cafes to discuss the project openly to enable community members to ask questions, challenge the project approaches, and discuss different aspects of the work. We feel these points of informal collaboration ultimately enriches our research and findings from the work. The team will continue to attend regular community calls throughout the development and data collection phase of the project, as part of building community trust with the work.  
We have developed a detailed and comprehensive consent form for 1:1 interviews, surveys, and the leadership workshops attached to this submission, which clearly outline the risks and benefits of the work, both on an individual and community level, to potential participants. We take the safety of participants seriously, and one of the strengths of engaging with Organizational Mycology as a third-party research organisation is that they are able to offer a different, more neutral perspective on challenges and strengths of the JupyterHub community, as well as bringing to bear expertise developed in similar work for other open source communities.  
The overarching goal of this project is to enhance and enrich contributor communities with practical strategies for empowering a more diverse array of contributors than previously.  
 

### **Outcome Transparency**  

*Overview of the team’s plan for communicating the findings of the research project, including a discussion of the limitations of the methods and findings and how these will be acknowledged in communications.*

The project intends to produce an open access report covering the findings and recommendations from the research as part of the deliverables. De-identified data from the 1:1 interviews and survey will also be published openly.  
The project will also be incorporating findings and recommendations into practical changes to the JupyterHub team documentation and team compass. As part of the project, the team will be working with the JupyerHub council to develop these and consult with the community on their implementation. Finally, *The Turing Way* researchers will incorporate generalisable findings from the project into the project guides to disseminate them to a wider audience.  
In previous reports by Organizational Mycology, methods sections have contained discussion of limitations and nuances around the qualitative and quantitive approaches used ([example](https://astropy-report.orgmycology.com/sections/methods)). We will ensure that reports produced as part of this project contain similar sections discussing nuances and limitations. As mentioned elsewhere, documentation accompanying datasets published will also include caveats and notation to make it clear the limitations of considering single quotes or points of evidence without considering the community holistically. 

### Interpretability

*Description of how the team will ensure that the outcomes of the research project are interpretable, explainable, and understandable to affected parties.*

Since the project's central aim is to improve the diversity of the JupyterHub community, our approach to ensuring the findings of the project are interpretable, explainable and understandable to affected parties aligns with our stakeholder engagement plans in 3.16 and our communication plans in 3.21.  
The team will communicate findings in English, and will produce a companion glossary for any unfamiliar terms which are necessary to explain in more depth beyond that available in other accompanying documentation.  
 

 

### Consent Form

**Consent Form: Participation in JupyterHub/The Turing Way Community Research Activities**

**SUMMARY OF KEY INFORMATION:**

You are being asked to participate in a research study conducted by Organizational Mycology on behalf of The Turing Way and JupyterHub. The Turing Way and JupyterHub have granted permission to conduct observations and interviews with members of these communities. This research is being conducted for the purposes of evaluating and improving the JupyterHub community and JupyterHub’s community-building strategies. Participation in the research is voluntary, and the decision to participate or not will have no impact on your relationship with the aforementioned communities. You were selected as a possible participant in this study because of your involvement in JupyterHub’s work. 

**PURPOSE:**

Data collection for this study is intended to: 

* Identify successes, challenges and opportunities to improve team dynamics within the JupyterHub community
* Facilitate team process and workflow improvement conversations
* Identify on-ramp pathways for community members to become JupyterHub developers
* Develop strategies, processes, and techniques for holding welcoming, inclusive, and productive community events
* Support mentors and mentees in the community
* Inform the revision and improvement of the JupyterHub Team Compass


**PROCEDURES:**

If you decide to participate, we will privately and confidentially schedule a time to interview you about your experiences in and opinions of the JupyterHub community. We expect the interview to last between 30 to 90 minutes. This interview will be held remotely over videoconference. We will not tell anyone whether you have been interviewed. Only if you consent to it, we will audio record our conversation for transcription. In some cases, we may request an additional interview; in these cases, participation is voluntary and declining the interview will have no impact on your relationship to the JupyterHub community.

**RISKS:**

*Psychological, mental, or emotional risks*. Though we do not anticipate significant risks to your participation in this research, some are possible. Asking you about your work may make you feel uncomfortable or decrease your performance in your job. 

*Privacy and data security*. We will make significant, extensive efforts to safeguard insights and qualitative data that you share. Specifically, we will:

* Store recordings off-cloud in a storage system which encrypts the files at rest on local disks. 
* Store encrypted archives / snapshots of this data in backblaze B2 for disaster recovery purposes.
* Transcribe recordings into text via a local GPU using WhisperX, and transcripts themselves will be worked on using a private Google Drive with access only available to the Organizational Mycology team.

Despite these extensive efforts, there is always a potential risk that individuals may learn of your views about the JupyterHub community. We will secure assurances from JupyterHub leadership that there will be no retaliation as a result of views expressed or changes in work patterns that could reasonably be associated with this study; however, such retaliation is technically possible. 

**BENEFITS:**

There is likely no direct, immediate benefit to you from participating in this study. When completed, however, results from the study will enable insights that will be practically useful to people in your position, JupyterHub’s leadership team, similar communities, and the broader open source software field as we all look for ways to improve community development, participation, inclusion, and productivity in the JupyterHub community.

**CONFIDENTIALITY**

Unless you grant permission to use your name, title, and/or quote you in any publications that may result from this research, the information you share will be confidential. We would like to record our interview so that we can use it for reference while proceeding with this study. We will not record our interview without your permission. If you do grant permission for this conversation to be recorded, you have the right to revoke recording permission and/or end the interview at any time.

If you do give permission for us to use your name, title, and/or quote you in any publications we will send the proposed text to you to review before publication. If you choose to not have the proposed information included in the publication we will not use it. Your decision will not affect your participation in the study and will have no impact on your relationship to the JupyterHub community.

* I grant permission for the use of my name, title, and/or quote, in any publications.
* I grant permission for the use of my quote ONLY, in any publication (i.e., use of anonymized quotes).
* I DO NOT grant permission for the use of my name, title, and/or quote in any publications.

**DATA USE, RETENTION, AND EUGDPR**

The categories of personal data you are being asked to consent to Organizational Mycology’s collection and use are your name, email address, role in the JupyterHub community, other employment information (e.g., organization and role), and qualitative descriptions of your experiences and insights from working in/engaging with the JupyterHub community. Your personal data will be transferred out of your home country and the European Union to Organizational Mycology, located in the United States and New Zealand. Under the EUGDPR, you have the right to request access to, rectify, erase and restrict the processing of your personal data. You also have the right to revoke this consent to use your personal data. If you feel Organizational Mycology has violated the EUGDPR, you have the right to file a complaint with the appropriate EU supervisory authority. 

De-identified quotes and paraphrased responses may be used in reports and other publications of the study’s results. 

This project will be completed by February 2025. **If you agree ONLY to the use of your data for this particular study,** all interview recordings will be stored in the aforementioned secure work space until two years after the final publication from this study. The recordings will then be destroyed. We will never share or play these audio recordings with anyone outside the research team, though we may share de-identified quotations from a transcript of your interview as part of reports and other outputs.

**If you agree to make your data available for inclusion in a permanent dataset,** your de-identified information from this study might be used inr future research studies. Your responses will first be subject to moderation (e.g., removing any information that is potentially sensitive or harmful; removing any content that violates the Codes of Conduct of JupyterHub and/or *The Turing Way*). Once your information passes through moderation, we will notify you and give you the opportunity to redact information or remove consent entirely. Any information shared for future research will NOT include your name or other personal identifying information. The dataset including your responses will then be published on a public repository after you have had a chance to review and approve it. 

* I consent to the use of my data for the particular study described above.
* I consent to the use of my data in a publicly-shared dataset.
* I understand that I can withdraw my consent for either activity at any time up until the public dataset has been published.

**RIGHT TO REFUSE OR WITHDRAW:**

You may refuse to participate and still receive any benefits you would receive if you were not in the study. You may change your mind about being in the study and quit after the study has started. You may withdraw consent for sharing of your responses at any time. We will treat your choice - to participate, not to participate, or to withdraw - as strictly confidential information. Our knowing about your choice will therefore have no negative effect on your reputation, position or employability within your community.

**QUESTIONS:**

If you have any questions about this research project, wish to withdrawal, or if you think you may have been injured or harmed as a result of your participation, please contact: Beth Duckles, [beth@orgmycology.com](mailto:beth@orgmycology.com) or Arielle Bennett, [abennett@turing.ac.uk](mailto:abennett@turing.ac.uk) 

PARTICIPATION IN RESEARCH IS VOLUNTARY. YOUR SIGNATURE BELOW WILL INDICATE THAT YOU HAVE DECIDED TO PARTICIPATE AS A RESEARCH SUBJECT IN THE STUDY DESCRIBED ABOVE, AND THAT YOU CONSENT TO THE USE OF YOUR PERSONAL DATA AS DESCRIBED ABOVE. YOU WILL BE GIVEN A SIGNED AND DATED COPY OF THIS FORM TO KEEP.

Name of Participant:  \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ 

## Signature of Participant or Legal Representative: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ Date: \_\_\_\_\_\_\_\_\_ Time: \_\_\_\_

 

### Fairness Statement

---

**All stakeholder groups in the JupyterHub community have their voices represented proportionally to their size and involvement in the project.**  
As part of embedding this operationally, the team are employing a variety of different methodologies to capture different stakeholders perspectives and opinions throughout the data gathering stage. There are also planned opportunities for the community to feedback on proposed outputs to flag unanticipated potential outcomes for recommendations, outside of the leadership workshops.  
**Outcomes result in opportunities for increased involvement and success, especially for non-leadership members of the community & participants in the research stand to gain a reasonable benefit comparable to the benefits of the JupyterHub leadership team.**

Central to the overarching aims of the project are concrete recommendations for process and pathway improvements which increase the overall diversity and vibrancy of the JupyterHub community. This position will not only drive the outputs produced as described elsewhere in this application but also be centred in the metrics used to assess the overall success of the project and its impact on community diversity.  
**Findings are generalizable to the extent possible and shared with other open source software/open science communities for reference in improvement efforts of their communities.**  
While the main focus of the project is to enhance the diversity of the JupyterHub community, the team recognise that some of the findings and recommendations will be applicable to other open source communities who are also looking to improve aspects of their approach to diversity, equity and inclusion as part of community building. We have therefore incorporated a stage into the project for reflection on which of the recommendations could be made project-agnostic, and serve as a template for others looking to do similar work. All outputs of the project are intended to be published open source, regardless, to support reuse in other contexts and communities.  
**Appendix III: Research Interview Questions**

---

We have developed preliminary protocols/guides for the interviews and leadership workshops. The questions are designed to facilitate a data collection process that enables us to answer the overall research questions. These research questions, however, may slightly shift throughout the project as early results shape our understanding of the community and its challenges. We do not expect the line of inquiry to substantially shift in terms of scope, depth, and risk to the participant or researchers. If this does occur, we will update the ethics documents for review. 

* Our research questions are below, with corresponding protocol questions in the sub-bullet points:
* What are the past and existing successes of the JupyterHub community?
  * Tell us about your involvement with the JupyterHub community?
	* What got you interested in the community?
	* What has kept you engaged?
	* Why do you contribute?
  * Tell me a bit about how your involvement in the JupyterHub community has benefitted…
	* Your own work?
	* Your career?
	* Your discipline?
	* Your connections to peers?
  * What do you think the public perception is of JupyterHub?
* What are the activities and actions that underpinned the past successes?
  * When you think about your involvement in the JupyterHub community, which events and activities stick out to you as positive experiences?
	* Probes: Could you tell me more about that (when, how it happened, what it entailed)
	* Why do you see that as a success?
  * What do you think the impact of these successes has been
	* For the community?
	* For your work?
	* For your discipline?
* What opportunities has the JupyterHub community missed, or not been able to leverage for impact, in the past?
  * When you think about your involvement with the JupyterHub community, what (if any) are the challenging or negative experiences?
	* Probes: Could you tell me more about that (when, how it happened, what it entailed)
  * What could the JupyterHub leadership do to make more of an impact?
* How can community development be improved?
  * What advice would you give the JupyterHub leadership to improve community development?
  * What does the JupyterHub community need more of?
* What does the developer community need?
  * What could the JupyterHub community do to better support the developers?
* What are the blockers to engagement with the JupyterHub community?
  * *For active developers/contributors*: What obstacles did you face in moving from a user or community member to developer/contributor? Have you seen peers struggle with similar/different things?
  * *For community members who are not yet active developers/contributors*: What has kept you from contributing to JupyterHub?
  * What would help?
* For the Voices of Jupyter component of the project, we will also focus on the general experiences of community members. Questions will include:
  * Tell me about your experience in the JupyterHub project, from the time you first engaged with it to the role you are in now
  * How is JupyterHub perceived in your field/industry?
* Leadership workshops
  * Strategy development
  * Future thinking
* Survey
  * Questions will be adapted on interview responses but will likely include the following topics:
	* What does the community do well?
	* Where could the community improve?
	  * For developers?
	  * For users?
	* What is the perception of JupyterHub in your field/community?

